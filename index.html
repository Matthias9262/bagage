<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8">
  <title>Démo Bagage OUIGO RA</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.10.0"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
  <style>
    body {
      margin: 0; background: #13002F; color: #fff;
      font-family: sans-serif; display: flex; flex-direction: column; align-items: center;
    }
    video, canvas {
      width: 100%; max-width: 480px;
      border-radius: 10px; margin-top: 1rem;
    }
    #status {
      margin-top: 1rem; font-size: 1.2rem;
    }
    #status.ok { color: #00FF88; }
    #status.nok { color: #FF3FA6; }
  </style>
</head>
<body>
  <h2>Démo RA OUIGO – Bagages</h2>
  <video id="video" autoplay muted playsinline></video>
  <canvas id="canvas"></canvas>
  <div id="status">Chargement...</div>

  <audio id="audio-success" src="success.mp3" preload="auto"></audio>
  <audio id="audio-detect" src="detect.mp3" preload="auto"></audio>

  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const statusEl = document.getElementById('status');
    const audioSuccess = document.getElementById('audio-success');
    const audioDetect = document.getElementById('audio-detect');

    let model, isCalibrated = false, scale = 1;

    // Calibration automatique : en supposant qu’une carte bancaire est visible
    const REF_WIDTH_CM = 8.5; // largeur carte bancaire

    async function setupCamera() {
      const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'environment' }, audio: false });
      video.srcObject = stream;
      return new Promise(resolve => video.onloadedmetadata = resolve);
    }

    function calibrateAuto(predictions) {
      const cardLike = predictions.find(p => p.class === "cell phone" || p.class === "remote" || p.class === "book");
      if (cardLike) {
        const [x, y, w, h] = cardLike.bbox;
        scale = REF_WIDTH_CM / w;
        isCalibrated = true;
        console.log("Calibration automatique OK");
      }
    }

    function play(audio) {
      if (!audio.paused) audio.pause();
      audio.currentTime = 0;
      audio.play();
    }

    function drawBox(x, y, w, h, color) {
      ctx.strokeStyle = color;
      ctx.lineWidth = 4;
      ctx.strokeRect(x, y, w, h);
    }

    async function detectFrame() {
      if (!model) return requestAnimationFrame(detectFrame);
      const predictions = await model.detect(video);
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      ctx.clearRect(0, 0, canvas.width, canvas.height);

      if (!isCalibrated) calibrateAuto(predictions);

      const bag = predictions.find(p => ['suitcase', 'handbag', 'backpack'].includes(p.class) && p.score > 0.6);
      if (bag) {
        const [x, y, w, h] = bag.bbox;
        drawBox(x, y, w, h, '#FF3FA6');
        if (scale > 0) {
          const widthCM = (w * scale).toFixed(1);
          statusEl.innerHTML = `Largeur estimée : <strong>${widthCM} cm</strong>`;
          const ok = widthCM <= 55;
          statusEl.className = ok ? 'ok' : 'nok';
          play(ok ? audioSuccess : audioDetect);
        } else {
          statusEl.textContent = "En attente de calibration...";
          statusEl.className = '';
        }
      } else {
        statusEl.textContent = "Aucun bagage détecté";
        statusEl.className = '';
      }

      requestAnimationFrame(detectFrame);
    }

    async function init() {
      await setupCamera();
      model = await cocoSsd.load();
      statusEl.textContent = "Modèle chargé. Détection en cours...";
      detectFrame();
    }

    init();
  </script>
</body>
</html>
