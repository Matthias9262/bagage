<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8" />
  <title>D√©tection Bagage + Marque + Capture Photo</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.20.0"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
  <script src="https://cdn.jsdelivr.net/npm/tesseract.js@4.0.2/dist/tesseract.min.js"></script>
  <style>
    body {
      background: #f7f7f7;
      font-family: Arial, sans-serif;
      text-align: center;
      padding: 20px;
    }
    h1 { color: #2a5ea5; }
    #container {
      position: relative;
      display: inline-block;
    }
    video, canvas {
      border-radius: 10px;
      width: 640px;
      height: 480px;
    }
    canvas {
      position: absolute;
      top: 0;
      left: 0;
    }
    #status {
      font-size: 1.1em;
      margin-top: 10px;
      font-weight: bold;
      min-height: 32px;
    }
    #instructions {
      font-style: italic;
      margin-bottom: 10px;
      max-width: 600px;
      margin-left: auto;
      margin-right: auto;
    }
    #captured-photo-container {
      margin-top: 20px;
    }
    #captured-photo {
      max-width: 320px;
      border-radius: 8px;
      box-shadow: 0 0 8px rgba(0,0,0,0.3);
    }
    #btn-capture {
      margin-top: 10px;
      cursor: pointer;
      font-size: 1em;
      padding: 6px 12px;
      border: none;
      border-radius: 6px;
      background-color: #2a5ea5;
      color: white;
      transition: background-color 0.3s ease;
    }
    #btn-capture:hover {
      background-color: #194785;
    }
  </style>
</head>
<body>
  <h1>üß≥ D√©tection Bagage + Marque + Capture Photo</h1>
  <div id="instructions">
    Placez une <strong>feuille A4 visible</strong> sur fond sombre pour calibrer la taille.<br/>
    Montrez un bagage avec un logo/label lisible (ex: Eastpak, Delsey) pour reconnaissance OCR.<br/>
    Patientez quelques secondes pour la lecture OCR.<br/>
    La photo sera captur√©e automatiquement quand un bagage cabine OK est d√©tect√©.
  </div>
  <div id="container">
    <video id="video" autoplay muted playsinline></video>
    <canvas id="canvas"></canvas>
  </div>
  <div id="status">Chargement du mod√®le...</div>

  <div id="captured-photo-container">
    <h3>üì∏ Photo captur√©e :</h3>
    <img id="captured-photo" alt="Photo bagage" />
    <br/>
    <button id="btn-capture">üì∑ Capturer maintenant</button>
  </div>

  <script>
    const video = document.getElementById("video");
    const canvas = document.getElementById("canvas");
    const ctx = canvas.getContext("2d");
    const statusEl = document.getElementById("status");

    const BAG_CLASSES = ['suitcase', 'backpack', 'handbag'];
    const CONFIDENCE_THRESHOLD = 0.5;
    const A4_WIDTH_CM = 21;

    const BAG_DATABASE = [
      { brand: "Eastpak", model: "Tranverz S", type: "suitcase", width: 32.5, height: 51 },
      { brand: "Delsey", model: "Turenne 55cm", type: "suitcase", width: 35, height: 55 },
      { brand: "Samsonite", model: "S'Cure Spinner 55", type: "suitcase", width: 40, height: 55 },
      { brand: "Cabin Max", model: "Metz 44L", type: "backpack", width: 35, height: 50 }
    ];

    let model, pixelPerCm = null;
    let ocrWorker = null;
    let lastOcrText = "";
    let lastOcrTime = 0;
    const OCR_COOLDOWN = 3000; // 3 sec entre lectures
    let lastCaptureTime = 0;
    const CAPTURE_COOLDOWN_MS = 5000; // 5 sec entre captures automatiques

    async function setupCamera() {
      const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "environment" } });
      video.srcObject = stream;
      return new Promise(resolve => {
        video.onloadedmetadata = () => {
          video.play();
          canvas.width = video.videoWidth;
          canvas.height = video.videoHeight;
          resolve();
        };
      });
    }

    function findBrightestRectangle(imageData) {
      const { data, width, height } = imageData;
      let boxes = [];
      const blockSize = 10;

      for (let y = 0; y < height; y += blockSize) {
        for (let x = 0; x < width; x += blockSize) {
          let brightnessSum = 0;
          for (let dy = 0; dy < blockSize; dy++) {
            for (let dx = 0; dx < blockSize; dx++) {
              const px = ((y + dy) * width + (x + dx)) * 4;
              const r = data[px], g = data[px + 1], b = data[px + 2];
              brightnessSum += (r + g + b) / 3;
            }
          }
          const avgBrightness = brightnessSum / (blockSize * blockSize);
          if (avgBrightness > 210) {
            boxes.push({ x, y, w: blockSize, h: blockSize });
          }
        }
      }

      if (boxes.length < 10) return null;

      let minX = Math.min(...boxes.map(b => b.x));
      let minY = Math.min(...boxes.map(b => b.y));
      let maxX = Math.max(...boxes.map(b => b.x + b.w));
      let maxY = Math.max(...boxes.map(b => b.y + b.h));

      const widthBox = maxX - minX;
      const heightBox = maxY - minY;
      const ratio = widthBox / heightBox;

      if (widthBox < 100 || heightBox < 150) return null;
      if (ratio < 0.6 || ratio > 0.9) return null;

      return { x: minX, y: minY, width: widthBox, height: heightBox, ratio };
    }

    async function doOcrOnBag(bbox) {
      if (!ocrWorker) return null;
      const now = Date.now();
      if (now - lastOcrTime < OCR_COOLDOWN) return null;

      const [x, y, w, h] = bbox;
      const imgData = ctx.getImageData(x, y, w, h);
      const canvasTmp = document.createElement('canvas');
      canvasTmp.width = w;
      canvasTmp.height = h;
      canvasTmp.getContext('2d').putImageData(imgData, 0, 0);

      lastOcrTime = now;
      const { data: { text } } = await ocrWorker.recognize(canvasTmp);
      lastOcrText = text.trim().toLowerCase();

      return lastOcrText;
    }

    function findBestMatch(type, widthCm, heightCm) {
      for (const bag of BAG_DATABASE) {
        if (bag.type !== type) continue;
        const wOk = Math.abs(bag.width - widthCm) / bag.width < 0.1;
        const hOk = Math.abs(bag.height - heightCm) / bag.height < 0.1;
        if (wOk && hOk) return bag;
      }
      return null;
    }

    function findBrandInText(text) {
      if (!text) return null;
      const brands = BAG_DATABASE.map(b => b.brand.toLowerCase());
      for (const brand of brands) {
        if (text.includes(brand)) return brand;
      }
      return null;
    }

    function capturePhoto() {
      const now = Date.now();
      if (now - lastCaptureTime < CAPTURE_COOLDOWN_MS) {
        // cooldown pour √©viter captures trop fr√©quentes
        return;
      }
      lastCaptureTime = now;
      const imgDataUrl = canvas.toDataURL("image/jpeg", 0.9);
      const imgElem = document.getElementById("captured-photo");
      imgElem.src = imgDataUrl;
    }

    async function detectFrame() {
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
      const a4 = findBrightestRectangle(imageData);

      if (a4) {
        ctx.strokeStyle = 'blue';
        ctx.lineWidth = 3;
        ctx.strokeRect(a4.x, a4.y, a4.width, a4.height);
        ctx.fillStyle = 'blue';
        ctx.font = "14px Arial";
        ctx.fillText("Feuille A4 d√©tect√©e", a4.x + 5, a4.y - 5);
        pixelPerCm = a4.width / A4_WIDTH_CM;
      } else {
        pixelPerCm = null;
        ctx.font = "16px Arial";
        ctx.fillStyle = "gray";
        ctx.fillText("‚ùó Feuille A4 non d√©tect√©e", 10, 20);
      }

      const predictions = await model.detect(video);
      let foundBag = false;

      for (const pred of predictions) {
        if (BAG_CLASSES.includes(pred.class) && pred.score > CONFIDENCE_THRESHOLD) {
          foundBag = true;
          const [x, y, w, h] = pred.bbox;

          ctx.strokeStyle = "orange";
          ctx.lineWidth = 2;
          ctx.strokeRect(x, y, w, h);
          ctx.fillStyle = "black";
          ctx.fillText(`${pred.class} ${(pred.score * 100).toFixed(1)}%`, x + 4, y - 4);

          if (pixelPerCm) {
            const widthCm = (w / pixelPerCm).toFixed(1);
            const heightCm = (h / pixelPerCm).toFixed(1);
            const ok = widthCm <= 35 && heightCm <= 55;

            ctx.fillStyle = ok ? "green" : "red";
            ctx.fillText(`~${widthCm}cm √ó ${heightCm}cm`, x + 4, y + h + 16);
            ctx.fillText(ok ? "‚úÖ Cabine OK" : "‚ùå Trop grand", x + 4, y + h + 32);

            const ocrText = await doOcrOnBag(pred.bbox);
            let brandDetected = null;
            if (ocrText) brandDetected = findBrandInText(ocrText);

            let match = null;
            if (brandDetected) {
              match = BAG_DATABASE.find(b => b.brand.toLowerCase() === brandDetected);
            } else {
              match = findBestMatch(pred.class, parseFloat(widthCm), parseFloat(heightCm));
            }

            if (match) {
              ctx.fillStyle = "#0055aa";
              ctx.fillText(`üîç Mod√®le estim√© : ${match.brand} ${match.model}`, x + 4, y + h + 48);
              statusEl.textContent = ok
                ? `‚úÖ Bagage OK: ${widthCm}√ó${heightCm}cm - Mod√®le estim√© : ${match.brand} ${match.model}`
                : `‚ùå Trop grand : ${widthCm}√ó${heightCm}cm - Mod√®le estim√© : ${match.brand} ${match.model}`;
            } else if (brandDetected) {
              ctx.fillStyle = "#0055aa";
              ctx.fillText(`üîç Marque d√©tect√©e : ${brandDetected}`, x + 4, y + h + 48);
              statusEl.textContent = `‚úÖ Marque d√©tect√©e : ${brandDetected} - Taille : ${widthCm}√ó${heightCm}cm`;
            } else {
              statusEl.textContent = ok
                ? `‚úÖ Bagage OK: ${widthCm}√ó${heightCm}cm - Mod√®le non reconnu`
                : `‚ùå Trop grand : ${widthCm}√ó${heightCm}cm - Mod√®le non reconnu`;
            }

            // Capture automatique si bagage cabine OK
            if (ok) {
              capturePhoto();
            }
          } else {
            statusEl.textContent = "üïµÔ∏è‚Äç‚ôÇÔ∏è A4 non d√©tect√©e ‚Äî calibration impossible";
          }
          break;
        }
      }

      if (!foundBag) {
        statusEl.textContent = "‚ùå Aucun bagage d√©tect√©";
      }

      requestAnimationFrame(detectFrame);
    }

    async function main() {
      await setupCamera();
      model = await cocoSsd.load();
      statusEl.textContent = "Mod√®le charg√©, initialisation OCR...";
      ocrWorker = Tesseract.createWorker({
        logger: m => {
          if (m.status === "recognizing text") statusEl.textContent = `OCR: ${Math.round(m.progress * 100)}%`;
        }
      });
      await ocrWorker.load();
      await ocrWorker.loadLanguage('eng');
      await ocrWorker.initialize('eng');
      statusEl.textContent = "Mod√®le charg√©, d√©tection en cours...";
      detectFrame();
    }

    document.getElementById("btn-capture").addEventListener("click", capturePhoto);

    main();
  </script>
</body>
</html>
